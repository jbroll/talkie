# homophone.tcl - Homophone correction using ELECTRA MLM
# Uses masked language modeling to compare probabilities of homophone alternatives
#
# Homophones are loaded from data/homophones.json, which is generated by
# src/pos_disambiguate.py from the pronunciation dictionary (en.dic).
# See data/HOMOPHONES.md for generation instructions.

package require gec
package require wordpiece

namespace eval homophone {
    # Homophones loaded from pronunciation dictionary analysis
    # Format: word -> list of alternatives (words with same pronunciation)
    variable homophones
    array set homophones {}

    # Multi-token homophones (contractions)
    # Format: {token_pattern} -> {single_token_alternatives}
    # Token IDs for common contractions:
    #   they=2027, you=2017, it=2009, we=2057, who=2040
    #   '=1005, re=2128, s=1055, ve=2310
    variable multitoken_homophones
    array set multitoken_homophones {}

    # Model state
    variable model ""
    variable request ""
    variable initialized 0
}

# Initialize the homophone correction system
proc homophone::init {args} {
    variable homophones
    variable model
    variable request
    variable initialized

    # Parse arguments
    set model_path ""
    set vocab_path ""
    set homophones_path ""
    set device "NPU"

    foreach {opt val} $args {
        switch -- $opt {
            -model { set model_path $val }
            -vocab { set vocab_path $val }
            -homophones { set homophones_path $val }
            -device { set device $val }
            default { error "Unknown option: $opt" }
        }
    }

    if {$model_path eq ""} {
        error "Missing required -model option"
    }
    if {$vocab_path eq ""} {
        error "Missing required -vocab option"
    }

    # Default homophones path from data directory
    if {$homophones_path eq ""} {
        # Look relative to model path (../../data/homophones.json from models/gec/)
        set data_dir [file normalize [file join [file dirname $model_path] ../../data]]
        set homophones_path [file join $data_dir homophones.json]
        if {![file exists $homophones_path]} {
            error "Homophones file not found at $homophones_path. See data/HOMOPHONES.md for generation."
        }
    }

    # Load vocabulary first (needed to filter homophones)
    wordpiece::load $vocab_path

    # Load homophones from JSON cache
    set count [load_homophones $homophones_path]

    # Load ELECTRA model
    set model [gec::load_model -path $model_path -device $device]
    set request [$model create_request]

    # Initialize multi-token homophones
    init_multitoken

    set initialized 1
    return $count
}

# Initialize multi-token homophone patterns (now done in load_homophones)
proc homophone::init_multitoken {} {
    variable multitoken_homophones
    # Multi-token patterns are now loaded directly in load_homophones
    # This function is kept for compatibility but does nothing extra
}

# Load homophones from JSON file
proc homophone::load_homophones {path} {
    variable homophones
    variable multitoken_homophones

    # Clear existing
    array unset homophones
    array unset multitoken_homophones

    # Read JSON file
    set fd [open $path r]
    set json [read $fd]
    close $fd

    # Parse JSON format: {"word": ["alt1", "alt2"], "word2": [...], ...}
    set count 0
    set in_vocab 0
    set multi_count 0

    # Find all entries by iterating through matches using -start
    set start 0
    set pattern {"([^"]+)":\s*\[([^\]]*)\]}

    while {[regexp -indices -start $start $pattern $json match_range word_range alts_range]} {
        set word [string range $json {*}$word_range]
        set alts_str [string range $json {*}$alts_range]

        # Parse ALL alternatives (including contractions)
        set all_alts {}
        set single_token_alts {}
        set alt_start 0
        while {[regexp -indices -start $alt_start {"([^"]+)"} $alts_str alt_match_range alt_range]} {
            set alt [string range $alts_str {*}$alt_range]
            lappend all_alts $alt

            # Check if it's a single token (not UNK, not contraction)
            set alt_id [wordpiece::token_to_id $alt]
            if {$alt_id != 100 && ![string match "*'*" $alt]} {
                lappend single_token_alts $alt
            }
            set alt_start [expr {[lindex $alt_match_range 1] + 1}]
        }

        # Store single-token homophones
        if {[llength $single_token_alts] >= 2} {
            set word_id [wordpiece::token_to_id $word]
            if {$word_id != 100 && ![string match "*'*" $word]} {
                set homophones($word) $single_token_alts
                incr in_vocab
            }
        }

        # Check if this word is multi-token with single-token alternatives
        set word_id [wordpiece::token_to_id $word]
        if {$word_id == 100 || [string match "*'*" $word]} {
            # Word is multi-token or has apostrophe - get its token sequence
            set tokens [wordpiece::encode $word 16]
            set token_ids {}
            for {set i 1} {$i < 16} {incr i} {
                set tid [lindex $tokens $i]
                if {$tid == 0 || $tid == 102} break
                lappend token_ids $tid
            }

            set num_tokens [llength $token_ids]
            if {$num_tokens >= 2 && $num_tokens <= 4 && [llength $single_token_alts] > 0} {
                # This multi-token word has single-token alternatives
                set key [join $token_ids ","]
                set alts_with_ids {}
                foreach alt $single_token_alts {
                    set alt_id [wordpiece::token_to_id $alt]
                    lappend alts_with_ids [list $alt $alt_id]
                }
                set multitoken_homophones($key) $alts_with_ids
                incr multi_count
            }
        }

        incr count

        # Move past this match
        set start [expr {[lindex $match_range 1] + 1}]
    }

    puts stderr "homophone: loaded $in_vocab single-token, $multi_count multi-token homophones (of $count total) from $path"
    return $in_vocab
}

# Clean up resources
proc homophone::cleanup {} {
    variable model
    variable request
    variable initialized

    if {$initialized} {
        catch { $request close }
        catch { $model close }
        set initialized 0
    }
}

# Softmax over a list of logits
proc homophone::softmax {logits} {
    # Find max for numerical stability
    set max_val [::tcl::mathfunc::max {*}$logits]

    # Compute exp(x - max) for each
    set exps {}
    set sum 0.0
    foreach x $logits {
        set e [expr {exp($x - $max_val)}]
        lappend exps $e
        set sum [expr {$sum + $e}]
    }

    # Normalize
    set probs {}
    foreach e $exps {
        lappend probs [expr {$e / $sum}]
    }
    return $probs
}

# Get probability of a specific token at a masked position
proc homophone::get_token_prob {logits token_id} {
    # logits is a flat list of vocab_size floats
    # Return the logit for the given token_id
    return [lindex $logits $token_id]
}

# Check if a word is a known homophone
proc homophone::is_homophone {word} {
    variable homophones
    return [info exists homophones($word)]
}

# Get homophone alternatives for a word
proc homophone::get_alternatives {word} {
    variable homophones

    if {![info exists homophones($word)]} {
        return [list $word]
    }
    return $homophones($word)
}

# Find multi-token homophone patterns in a token sequence
# Returns list of {start_pos length pattern_key alternatives}
# Longer patterns take priority; overlapping patterns are skipped
proc homophone::find_multitoken_patterns {tokens} {
    variable multitoken_homophones

    set patterns {}
    set len [llength $tokens]
    set covered {}  ;# Positions already covered by a pattern

    for {set i 1} {$i < $len - 1} {incr i} {
        # Skip if this position is already covered
        if {$i in $covered} continue

        set t1 [lindex $tokens $i]

        # Skip if we hit special tokens or padding
        if {$t1 == 0 || $t1 == 102} break

        # Try pattern lengths from longest to shortest (prefer longer matches)
        foreach pattern_len {4 3 2} {
            if {$i + $pattern_len > $len} continue

            set token_ids {}
            for {set j 0} {$j < $pattern_len} {incr j} {
                set tid [lindex $tokens [expr {$i + $j}]]
                if {$tid == 0 || $tid == 102} break
                lappend token_ids $tid
            }

            if {[llength $token_ids] == $pattern_len} {
                set key [join $token_ids ","]
                if {[info exists multitoken_homophones($key)]} {
                    lappend patterns [list $i $pattern_len $key $multitoken_homophones($key)]
                    # Mark these positions as covered
                    for {set j 0} {$j < $pattern_len} {incr j} {
                        lappend covered [expr {$i + $j}]
                    }
                    break  ;# Found a match, don't check shorter patterns
                }
            }
        }
    }

    return $patterns
}

# Score a token at a masked position
proc homophone::score_at_position {tokens mask pos token_id} {
    variable request

    # Create masked input
    set masked_tokens $tokens
    lset masked_tokens $pos 103  ;# [MASK]

    $request set_input 0 $masked_tokens
    $request set_input 1 $mask
    $request infer

    set output [$request get_output 0]
    set logits [dict get $output data]

    set vocab_size 30522
    set start_idx [expr {$pos * $vocab_size}]
    return [lindex $logits [expr {$start_idx + $token_id}]]
}

# Correct multi-token homophones (contractions) in token sequence
# Returns modified tokens list
proc homophone::correct_multitoken {tokens mask} {
    variable multitoken_homophones

    set patterns [find_multitoken_patterns $tokens]
    if {[llength $patterns] == 0} {
        return $tokens
    }

    # Process patterns in reverse order to maintain positions
    set patterns [lsort -integer -decreasing -index 0 $patterns]

    set result_tokens $tokens
    foreach pattern $patterns {
        lassign $pattern start_pos length key alternatives

        # Create neutral context: mask position + pad remaining tokens
        # This gives fair comparison between multi-token and single-token
        set neutral_tokens $result_tokens
        lset neutral_tokens $start_pos 103  ;# [MASK]
        for {set j 1} {$j < $length} {incr j} {
            lset neutral_tokens [expr {$start_pos + $j}] 0
        }
        set neutral_mask [wordpiece::attention_mask $neutral_tokens]

        # Score all candidates in the same neutral context
        set t1 [lindex $result_tokens $start_pos]
        set best_id $t1
        set best_score [score_at_position $neutral_tokens $neutral_mask $start_pos $t1]

        foreach alt $alternatives {
            lassign $alt alt_word alt_id
            set alt_score [score_at_position $neutral_tokens $neutral_mask $start_pos $alt_id]

            if {$alt_score > $best_score} {
                set best_score $alt_score
                set best_id $alt_id
            }
        }

        # Apply if a single-token alternative wins
        if {$best_id != $t1} {
            lset result_tokens $start_pos $best_id
            for {set j 1} {$j < $length} {incr j} {
                lset result_tokens [expr {$start_pos + $j}] 0
            }
        }
    }

    return $result_tokens
}

# Correct homophones in text using ELECTRA MLM
proc homophone::correct {text} {
    variable request
    variable initialized

    if {!$initialized} {
        error "homophone::init must be called first"
    }

    # Tokenize the text
    set tokens [wordpiece::encode $text 64]
    set mask [wordpiece::attention_mask $tokens]

    # First pass: correct multi-token homophones (contractions)
    set tokens [correct_multitoken $tokens $mask]
    # Update attention mask after multi-token corrections
    set mask [wordpiece::attention_mask $tokens]

    # Second pass: find positions with single-token homophones
    set corrections {}
    set seq_len [llength $tokens]

    for {set pos 1} {$pos < $seq_len - 1} {incr pos} {
        set token_id [lindex $tokens $pos]

        # Skip padding and special tokens
        if {$token_id == 0 || $token_id == 101 || $token_id == 102} {
            continue
        }

        # Get the token string
        set token_str [wordpiece::id_to_token $token_id]

        # Skip subword tokens (##prefix)
        if {[string match "##*" $token_str]} {
            continue
        }

        # Check if this is a homophone
        if {![is_homophone $token_str]} {
            continue
        }

        # Get alternatives
        set alts [get_alternatives $token_str]

        # Skip if only one alternative (shouldn't happen)
        if {[llength $alts] <= 1} {
            continue
        }

        # Create masked input - replace this position with [MASK] (103)
        set masked_tokens $tokens
        lset masked_tokens $pos 103

        # Run inference
        $request set_input 0 $masked_tokens
        $request set_input 1 $mask
        $request infer

        # Get output logits
        set output [$request get_output 0]
        set logits [dict get $output data]

        # Extract logits for this position (shape is [1, 64, 30522])
        # Position in flat array: pos * vocab_size
        set vocab_size 30522
        set start_idx [expr {$pos * $vocab_size}]

        # Get logits for each alternative
        set best_alt $token_str
        set best_logit -1e30

        foreach alt $alts {
            set alt_id [wordpiece::token_to_id $alt]
            if {$alt_id == 100} {
                # [UNK] - skip alternatives not in vocab
                continue
            }
            set logit [lindex $logits [expr {$start_idx + $alt_id}]]

            if {$logit > $best_logit} {
                set best_logit $logit
                set best_alt $alt
            }
        }

        # Record correction if different
        if {$best_alt ne $token_str} {
            lappend corrections [list $pos $token_str $best_alt $best_logit]
        }
    }

    # Apply single-token corrections to the (possibly multi-token corrected) tokens
    foreach correction $corrections {
        lassign $correction pos old_token new_token logit
        set new_id [wordpiece::token_to_id $new_token]
        lset tokens $pos $new_id
    }

    # Always decode - multi-token corrections may have been applied
    return [wordpiece::decode $tokens]
}

# Correct text and return detailed results
proc homophone::correct_verbose {text} {
    variable request
    variable initialized
    variable word_to_group

    if {!$initialized} {
        error "homophone::init must be called first"
    }

    set tokens [wordpiece::encode $text 64]
    set mask [wordpiece::attention_mask $tokens]

    set results {}
    set seq_len [llength $tokens]

    for {set pos 1} {$pos < $seq_len - 1} {incr pos} {
        set token_id [lindex $tokens $pos]

        if {$token_id == 0 || $token_id == 101 || $token_id == 102} {
            continue
        }

        set token_str [wordpiece::id_to_token $token_id]

        if {[string match "##*" $token_str]} {
            continue
        }

        if {![is_homophone $token_str]} {
            continue
        }

        set alts [get_alternatives $token_str]

        # Create masked input
        set masked_tokens $tokens
        lset masked_tokens $pos 103

        $request set_input 0 $masked_tokens
        $request set_input 1 $mask
        $request infer

        set output [$request get_output 0]
        set logits [dict get $output data]

        set vocab_size 30522
        set start_idx [expr {$pos * $vocab_size}]

        # Get all alternative scores
        set alt_scores {}
        foreach alt $alts {
            set alt_id [wordpiece::token_to_id $alt]
            if {$alt_id != 100} {
                set logit [lindex $logits [expr {$start_idx + $alt_id}]]
                lappend alt_scores [list $alt $logit]
            }
        }

        # Sort by score descending
        set alt_scores [lsort -real -decreasing -index 1 $alt_scores]

        lappend results [dict create \
            position $pos \
            original $token_str \
            alternatives $alt_scores \
            best [lindex [lindex $alt_scores 0] 0]]
    }

    return $results
}

# Package export
package provide homophone 1.0
